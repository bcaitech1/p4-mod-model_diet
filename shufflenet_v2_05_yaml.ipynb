{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/pstage4gun\n"
     ]
    }
   ],
   "source": [
    "# %cd pstage4gun"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torchvision\n",
    "\n",
    "class Shufflenet_v205(nn.Module):\n",
    "    def __init__(self, num_classes:int = 9):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.shufflenet_v2_x0_5(pretrained=True)\n",
    "        self.model.fc = torch.nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shufflenet_v205(\n",
      "  (model): ShuffleNetV2(\n",
      "    (conv1): Sequential(\n",
      "      (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (stage2): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n",
      "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
      "          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage3): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n",
      "          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (stage4): Sequential(\n",
      "      (0): InvertedResidual(\n",
      "        (branch1): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (4): ReLU(inplace=True)\n",
      "        )\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (branch1): Sequential()\n",
      "        (branch2): Sequential(\n",
      "          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
      "          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (7): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (conv5): Sequential(\n",
      "      (0): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "    )\n",
      "    (fc): Linear(in_features=1024, out_features=9, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ShModel = Shufflenet_v205()\n",
    "print(ShModel)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.conv1.0.weight\n",
      "model.conv1.1.weight\n",
      "model.conv1.1.bias\n",
      "model.conv1.1.running_mean\n",
      "model.conv1.1.running_var\n",
      "model.conv1.1.num_batches_tracked\n",
      "model.stage2.0.branch1.0.weight\n",
      "model.stage2.0.branch1.1.weight\n",
      "model.stage2.0.branch1.1.bias\n",
      "model.stage2.0.branch1.1.running_mean\n",
      "model.stage2.0.branch1.1.running_var\n",
      "model.stage2.0.branch1.1.num_batches_tracked\n",
      "model.stage2.0.branch1.2.weight\n",
      "model.stage2.0.branch1.3.weight\n",
      "model.stage2.0.branch1.3.bias\n",
      "model.stage2.0.branch1.3.running_mean\n",
      "model.stage2.0.branch1.3.running_var\n",
      "model.stage2.0.branch1.3.num_batches_tracked\n",
      "model.stage2.0.branch2.0.weight\n",
      "model.stage2.0.branch2.1.weight\n",
      "model.stage2.0.branch2.1.bias\n",
      "model.stage2.0.branch2.1.running_mean\n",
      "model.stage2.0.branch2.1.running_var\n",
      "model.stage2.0.branch2.1.num_batches_tracked\n",
      "model.stage2.0.branch2.3.weight\n",
      "model.stage2.0.branch2.4.weight\n",
      "model.stage2.0.branch2.4.bias\n",
      "model.stage2.0.branch2.4.running_mean\n",
      "model.stage2.0.branch2.4.running_var\n",
      "model.stage2.0.branch2.4.num_batches_tracked\n",
      "model.stage2.0.branch2.5.weight\n",
      "model.stage2.0.branch2.6.weight\n",
      "model.stage2.0.branch2.6.bias\n",
      "model.stage2.0.branch2.6.running_mean\n",
      "model.stage2.0.branch2.6.running_var\n",
      "model.stage2.0.branch2.6.num_batches_tracked\n",
      "model.stage2.1.branch2.0.weight\n",
      "model.stage2.1.branch2.1.weight\n",
      "model.stage2.1.branch2.1.bias\n",
      "model.stage2.1.branch2.1.running_mean\n",
      "model.stage2.1.branch2.1.running_var\n",
      "model.stage2.1.branch2.1.num_batches_tracked\n",
      "model.stage2.1.branch2.3.weight\n",
      "model.stage2.1.branch2.4.weight\n",
      "model.stage2.1.branch2.4.bias\n",
      "model.stage2.1.branch2.4.running_mean\n",
      "model.stage2.1.branch2.4.running_var\n",
      "model.stage2.1.branch2.4.num_batches_tracked\n",
      "model.stage2.1.branch2.5.weight\n",
      "model.stage2.1.branch2.6.weight\n",
      "model.stage2.1.branch2.6.bias\n",
      "model.stage2.1.branch2.6.running_mean\n",
      "model.stage2.1.branch2.6.running_var\n",
      "model.stage2.1.branch2.6.num_batches_tracked\n",
      "model.stage2.2.branch2.0.weight\n",
      "model.stage2.2.branch2.1.weight\n",
      "model.stage2.2.branch2.1.bias\n",
      "model.stage2.2.branch2.1.running_mean\n",
      "model.stage2.2.branch2.1.running_var\n",
      "model.stage2.2.branch2.1.num_batches_tracked\n",
      "model.stage2.2.branch2.3.weight\n",
      "model.stage2.2.branch2.4.weight\n",
      "model.stage2.2.branch2.4.bias\n",
      "model.stage2.2.branch2.4.running_mean\n",
      "model.stage2.2.branch2.4.running_var\n",
      "model.stage2.2.branch2.4.num_batches_tracked\n",
      "model.stage2.2.branch2.5.weight\n",
      "model.stage2.2.branch2.6.weight\n",
      "model.stage2.2.branch2.6.bias\n",
      "model.stage2.2.branch2.6.running_mean\n",
      "model.stage2.2.branch2.6.running_var\n",
      "model.stage2.2.branch2.6.num_batches_tracked\n",
      "model.stage2.3.branch2.0.weight\n",
      "model.stage2.3.branch2.1.weight\n",
      "model.stage2.3.branch2.1.bias\n",
      "model.stage2.3.branch2.1.running_mean\n",
      "model.stage2.3.branch2.1.running_var\n",
      "model.stage2.3.branch2.1.num_batches_tracked\n",
      "model.stage2.3.branch2.3.weight\n",
      "model.stage2.3.branch2.4.weight\n",
      "model.stage2.3.branch2.4.bias\n",
      "model.stage2.3.branch2.4.running_mean\n",
      "model.stage2.3.branch2.4.running_var\n",
      "model.stage2.3.branch2.4.num_batches_tracked\n",
      "model.stage2.3.branch2.5.weight\n",
      "model.stage2.3.branch2.6.weight\n",
      "model.stage2.3.branch2.6.bias\n",
      "model.stage2.3.branch2.6.running_mean\n",
      "model.stage2.3.branch2.6.running_var\n",
      "model.stage2.3.branch2.6.num_batches_tracked\n",
      "model.stage3.0.branch1.0.weight\n",
      "model.stage3.0.branch1.1.weight\n",
      "model.stage3.0.branch1.1.bias\n",
      "model.stage3.0.branch1.1.running_mean\n",
      "model.stage3.0.branch1.1.running_var\n",
      "model.stage3.0.branch1.1.num_batches_tracked\n",
      "model.stage3.0.branch1.2.weight\n",
      "model.stage3.0.branch1.3.weight\n",
      "model.stage3.0.branch1.3.bias\n",
      "model.stage3.0.branch1.3.running_mean\n",
      "model.stage3.0.branch1.3.running_var\n",
      "model.stage3.0.branch1.3.num_batches_tracked\n",
      "model.stage3.0.branch2.0.weight\n",
      "model.stage3.0.branch2.1.weight\n",
      "model.stage3.0.branch2.1.bias\n",
      "model.stage3.0.branch2.1.running_mean\n",
      "model.stage3.0.branch2.1.running_var\n",
      "model.stage3.0.branch2.1.num_batches_tracked\n",
      "model.stage3.0.branch2.3.weight\n",
      "model.stage3.0.branch2.4.weight\n",
      "model.stage3.0.branch2.4.bias\n",
      "model.stage3.0.branch2.4.running_mean\n",
      "model.stage3.0.branch2.4.running_var\n",
      "model.stage3.0.branch2.4.num_batches_tracked\n",
      "model.stage3.0.branch2.5.weight\n",
      "model.stage3.0.branch2.6.weight\n",
      "model.stage3.0.branch2.6.bias\n",
      "model.stage3.0.branch2.6.running_mean\n",
      "model.stage3.0.branch2.6.running_var\n",
      "model.stage3.0.branch2.6.num_batches_tracked\n",
      "model.stage3.1.branch2.0.weight\n",
      "model.stage3.1.branch2.1.weight\n",
      "model.stage3.1.branch2.1.bias\n",
      "model.stage3.1.branch2.1.running_mean\n",
      "model.stage3.1.branch2.1.running_var\n",
      "model.stage3.1.branch2.1.num_batches_tracked\n",
      "model.stage3.1.branch2.3.weight\n",
      "model.stage3.1.branch2.4.weight\n",
      "model.stage3.1.branch2.4.bias\n",
      "model.stage3.1.branch2.4.running_mean\n",
      "model.stage3.1.branch2.4.running_var\n",
      "model.stage3.1.branch2.4.num_batches_tracked\n",
      "model.stage3.1.branch2.5.weight\n",
      "model.stage3.1.branch2.6.weight\n",
      "model.stage3.1.branch2.6.bias\n",
      "model.stage3.1.branch2.6.running_mean\n",
      "model.stage3.1.branch2.6.running_var\n",
      "model.stage3.1.branch2.6.num_batches_tracked\n",
      "model.stage3.2.branch2.0.weight\n",
      "model.stage3.2.branch2.1.weight\n",
      "model.stage3.2.branch2.1.bias\n",
      "model.stage3.2.branch2.1.running_mean\n",
      "model.stage3.2.branch2.1.running_var\n",
      "model.stage3.2.branch2.1.num_batches_tracked\n",
      "model.stage3.2.branch2.3.weight\n",
      "model.stage3.2.branch2.4.weight\n",
      "model.stage3.2.branch2.4.bias\n",
      "model.stage3.2.branch2.4.running_mean\n",
      "model.stage3.2.branch2.4.running_var\n",
      "model.stage3.2.branch2.4.num_batches_tracked\n",
      "model.stage3.2.branch2.5.weight\n",
      "model.stage3.2.branch2.6.weight\n",
      "model.stage3.2.branch2.6.bias\n",
      "model.stage3.2.branch2.6.running_mean\n",
      "model.stage3.2.branch2.6.running_var\n",
      "model.stage3.2.branch2.6.num_batches_tracked\n",
      "model.stage3.3.branch2.0.weight\n",
      "model.stage3.3.branch2.1.weight\n",
      "model.stage3.3.branch2.1.bias\n",
      "model.stage3.3.branch2.1.running_mean\n",
      "model.stage3.3.branch2.1.running_var\n",
      "model.stage3.3.branch2.1.num_batches_tracked\n",
      "model.stage3.3.branch2.3.weight\n",
      "model.stage3.3.branch2.4.weight\n",
      "model.stage3.3.branch2.4.bias\n",
      "model.stage3.3.branch2.4.running_mean\n",
      "model.stage3.3.branch2.4.running_var\n",
      "model.stage3.3.branch2.4.num_batches_tracked\n",
      "model.stage3.3.branch2.5.weight\n",
      "model.stage3.3.branch2.6.weight\n",
      "model.stage3.3.branch2.6.bias\n",
      "model.stage3.3.branch2.6.running_mean\n",
      "model.stage3.3.branch2.6.running_var\n",
      "model.stage3.3.branch2.6.num_batches_tracked\n",
      "model.stage3.4.branch2.0.weight\n",
      "model.stage3.4.branch2.1.weight\n",
      "model.stage3.4.branch2.1.bias\n",
      "model.stage3.4.branch2.1.running_mean\n",
      "model.stage3.4.branch2.1.running_var\n",
      "model.stage3.4.branch2.1.num_batches_tracked\n",
      "model.stage3.4.branch2.3.weight\n",
      "model.stage3.4.branch2.4.weight\n",
      "model.stage3.4.branch2.4.bias\n",
      "model.stage3.4.branch2.4.running_mean\n",
      "model.stage3.4.branch2.4.running_var\n",
      "model.stage3.4.branch2.4.num_batches_tracked\n",
      "model.stage3.4.branch2.5.weight\n",
      "model.stage3.4.branch2.6.weight\n",
      "model.stage3.4.branch2.6.bias\n",
      "model.stage3.4.branch2.6.running_mean\n",
      "model.stage3.4.branch2.6.running_var\n",
      "model.stage3.4.branch2.6.num_batches_tracked\n",
      "model.stage3.5.branch2.0.weight\n",
      "model.stage3.5.branch2.1.weight\n",
      "model.stage3.5.branch2.1.bias\n",
      "model.stage3.5.branch2.1.running_mean\n",
      "model.stage3.5.branch2.1.running_var\n",
      "model.stage3.5.branch2.1.num_batches_tracked\n",
      "model.stage3.5.branch2.3.weight\n",
      "model.stage3.5.branch2.4.weight\n",
      "model.stage3.5.branch2.4.bias\n",
      "model.stage3.5.branch2.4.running_mean\n",
      "model.stage3.5.branch2.4.running_var\n",
      "model.stage3.5.branch2.4.num_batches_tracked\n",
      "model.stage3.5.branch2.5.weight\n",
      "model.stage3.5.branch2.6.weight\n",
      "model.stage3.5.branch2.6.bias\n",
      "model.stage3.5.branch2.6.running_mean\n",
      "model.stage3.5.branch2.6.running_var\n",
      "model.stage3.5.branch2.6.num_batches_tracked\n",
      "model.stage3.6.branch2.0.weight\n",
      "model.stage3.6.branch2.1.weight\n",
      "model.stage3.6.branch2.1.bias\n",
      "model.stage3.6.branch2.1.running_mean\n",
      "model.stage3.6.branch2.1.running_var\n",
      "model.stage3.6.branch2.1.num_batches_tracked\n",
      "model.stage3.6.branch2.3.weight\n",
      "model.stage3.6.branch2.4.weight\n",
      "model.stage3.6.branch2.4.bias\n",
      "model.stage3.6.branch2.4.running_mean\n",
      "model.stage3.6.branch2.4.running_var\n",
      "model.stage3.6.branch2.4.num_batches_tracked\n",
      "model.stage3.6.branch2.5.weight\n",
      "model.stage3.6.branch2.6.weight\n",
      "model.stage3.6.branch2.6.bias\n",
      "model.stage3.6.branch2.6.running_mean\n",
      "model.stage3.6.branch2.6.running_var\n",
      "model.stage3.6.branch2.6.num_batches_tracked\n",
      "model.stage3.7.branch2.0.weight\n",
      "model.stage3.7.branch2.1.weight\n",
      "model.stage3.7.branch2.1.bias\n",
      "model.stage3.7.branch2.1.running_mean\n",
      "model.stage3.7.branch2.1.running_var\n",
      "model.stage3.7.branch2.1.num_batches_tracked\n",
      "model.stage3.7.branch2.3.weight\n",
      "model.stage3.7.branch2.4.weight\n",
      "model.stage3.7.branch2.4.bias\n",
      "model.stage3.7.branch2.4.running_mean\n",
      "model.stage3.7.branch2.4.running_var\n",
      "model.stage3.7.branch2.4.num_batches_tracked\n",
      "model.stage3.7.branch2.5.weight\n",
      "model.stage3.7.branch2.6.weight\n",
      "model.stage3.7.branch2.6.bias\n",
      "model.stage3.7.branch2.6.running_mean\n",
      "model.stage3.7.branch2.6.running_var\n",
      "model.stage3.7.branch2.6.num_batches_tracked\n",
      "model.stage4.0.branch1.0.weight\n",
      "model.stage4.0.branch1.1.weight\n",
      "model.stage4.0.branch1.1.bias\n",
      "model.stage4.0.branch1.1.running_mean\n",
      "model.stage4.0.branch1.1.running_var\n",
      "model.stage4.0.branch1.1.num_batches_tracked\n",
      "model.stage4.0.branch1.2.weight\n",
      "model.stage4.0.branch1.3.weight\n",
      "model.stage4.0.branch1.3.bias\n",
      "model.stage4.0.branch1.3.running_mean\n",
      "model.stage4.0.branch1.3.running_var\n",
      "model.stage4.0.branch1.3.num_batches_tracked\n",
      "model.stage4.0.branch2.0.weight\n",
      "model.stage4.0.branch2.1.weight\n",
      "model.stage4.0.branch2.1.bias\n",
      "model.stage4.0.branch2.1.running_mean\n",
      "model.stage4.0.branch2.1.running_var\n",
      "model.stage4.0.branch2.1.num_batches_tracked\n",
      "model.stage4.0.branch2.3.weight\n",
      "model.stage4.0.branch2.4.weight\n",
      "model.stage4.0.branch2.4.bias\n",
      "model.stage4.0.branch2.4.running_mean\n",
      "model.stage4.0.branch2.4.running_var\n",
      "model.stage4.0.branch2.4.num_batches_tracked\n",
      "model.stage4.0.branch2.5.weight\n",
      "model.stage4.0.branch2.6.weight\n",
      "model.stage4.0.branch2.6.bias\n",
      "model.stage4.0.branch2.6.running_mean\n",
      "model.stage4.0.branch2.6.running_var\n",
      "model.stage4.0.branch2.6.num_batches_tracked\n",
      "model.stage4.1.branch2.0.weight\n",
      "model.stage4.1.branch2.1.weight\n",
      "model.stage4.1.branch2.1.bias\n",
      "model.stage4.1.branch2.1.running_mean\n",
      "model.stage4.1.branch2.1.running_var\n",
      "model.stage4.1.branch2.1.num_batches_tracked\n",
      "model.stage4.1.branch2.3.weight\n",
      "model.stage4.1.branch2.4.weight\n",
      "model.stage4.1.branch2.4.bias\n",
      "model.stage4.1.branch2.4.running_mean\n",
      "model.stage4.1.branch2.4.running_var\n",
      "model.stage4.1.branch2.4.num_batches_tracked\n",
      "model.stage4.1.branch2.5.weight\n",
      "model.stage4.1.branch2.6.weight\n",
      "model.stage4.1.branch2.6.bias\n",
      "model.stage4.1.branch2.6.running_mean\n",
      "model.stage4.1.branch2.6.running_var\n",
      "model.stage4.1.branch2.6.num_batches_tracked\n",
      "model.stage4.2.branch2.0.weight\n",
      "model.stage4.2.branch2.1.weight\n",
      "model.stage4.2.branch2.1.bias\n",
      "model.stage4.2.branch2.1.running_mean\n",
      "model.stage4.2.branch2.1.running_var\n",
      "model.stage4.2.branch2.1.num_batches_tracked\n",
      "model.stage4.2.branch2.3.weight\n",
      "model.stage4.2.branch2.4.weight\n",
      "model.stage4.2.branch2.4.bias\n",
      "model.stage4.2.branch2.4.running_mean\n",
      "model.stage4.2.branch2.4.running_var\n",
      "model.stage4.2.branch2.4.num_batches_tracked\n",
      "model.stage4.2.branch2.5.weight\n",
      "model.stage4.2.branch2.6.weight\n",
      "model.stage4.2.branch2.6.bias\n",
      "model.stage4.2.branch2.6.running_mean\n",
      "model.stage4.2.branch2.6.running_var\n",
      "model.stage4.2.branch2.6.num_batches_tracked\n",
      "model.stage4.3.branch2.0.weight\n",
      "model.stage4.3.branch2.1.weight\n",
      "model.stage4.3.branch2.1.bias\n",
      "model.stage4.3.branch2.1.running_mean\n",
      "model.stage4.3.branch2.1.running_var\n",
      "model.stage4.3.branch2.1.num_batches_tracked\n",
      "model.stage4.3.branch2.3.weight\n",
      "model.stage4.3.branch2.4.weight\n",
      "model.stage4.3.branch2.4.bias\n",
      "model.stage4.3.branch2.4.running_mean\n",
      "model.stage4.3.branch2.4.running_var\n",
      "model.stage4.3.branch2.4.num_batches_tracked\n",
      "model.stage4.3.branch2.5.weight\n",
      "model.stage4.3.branch2.6.weight\n",
      "model.stage4.3.branch2.6.bias\n",
      "model.stage4.3.branch2.6.running_mean\n",
      "model.stage4.3.branch2.6.running_var\n",
      "model.stage4.3.branch2.6.num_batches_tracked\n",
      "model.conv5.0.weight\n",
      "model.conv5.1.weight\n",
      "model.conv5.1.bias\n",
      "model.conv5.1.running_mean\n",
      "model.conv5.1.running_var\n",
      "model.conv5.1.num_batches_tracked\n",
      "model.fc.weight\n",
      "model.fc.bias\n"
     ]
    }
   ],
   "source": [
    "print(*ShModel.state_dict().keys(), sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n"
     ]
    }
   ],
   "source": [
    "print(len(ShModel.state_dict()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from src.utils.common import get_label_counts, read_yaml\n",
    "from src.model import Model\n",
    "\n",
    "model_config = read_yaml(cfg=\"configs/model/shufflenet_v2_05_base.yaml\")\n",
    "shufflenet_v2_05_base = Model(cfg=model_config)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.0.conv.weight\n",
      "model.0.bn.weight\n",
      "model.0.bn.bias\n",
      "model.0.bn.running_mean\n",
      "model.0.bn.running_var\n",
      "model.0.bn.num_batches_tracked\n",
      "model.2.0.branch1.0.weight\n",
      "model.2.0.branch1.1.weight\n",
      "model.2.0.branch1.1.bias\n",
      "model.2.0.branch1.1.running_mean\n",
      "model.2.0.branch1.1.running_var\n",
      "model.2.0.branch1.1.num_batches_tracked\n",
      "model.2.0.branch1.2.weight\n",
      "model.2.0.branch1.3.weight\n",
      "model.2.0.branch1.3.bias\n",
      "model.2.0.branch1.3.running_mean\n",
      "model.2.0.branch1.3.running_var\n",
      "model.2.0.branch1.3.num_batches_tracked\n",
      "model.2.0.branch2.0.weight\n",
      "model.2.0.branch2.1.weight\n",
      "model.2.0.branch2.1.bias\n",
      "model.2.0.branch2.1.running_mean\n",
      "model.2.0.branch2.1.running_var\n",
      "model.2.0.branch2.1.num_batches_tracked\n",
      "model.2.0.branch2.3.weight\n",
      "model.2.0.branch2.4.weight\n",
      "model.2.0.branch2.4.bias\n",
      "model.2.0.branch2.4.running_mean\n",
      "model.2.0.branch2.4.running_var\n",
      "model.2.0.branch2.4.num_batches_tracked\n",
      "model.2.0.branch2.5.weight\n",
      "model.2.0.branch2.6.weight\n",
      "model.2.0.branch2.6.bias\n",
      "model.2.0.branch2.6.running_mean\n",
      "model.2.0.branch2.6.running_var\n",
      "model.2.0.branch2.6.num_batches_tracked\n",
      "model.3.0.branch2.0.weight\n",
      "model.3.0.branch2.1.weight\n",
      "model.3.0.branch2.1.bias\n",
      "model.3.0.branch2.1.running_mean\n",
      "model.3.0.branch2.1.running_var\n",
      "model.3.0.branch2.1.num_batches_tracked\n",
      "model.3.0.branch2.3.weight\n",
      "model.3.0.branch2.4.weight\n",
      "model.3.0.branch2.4.bias\n",
      "model.3.0.branch2.4.running_mean\n",
      "model.3.0.branch2.4.running_var\n",
      "model.3.0.branch2.4.num_batches_tracked\n",
      "model.3.0.branch2.5.weight\n",
      "model.3.0.branch2.6.weight\n",
      "model.3.0.branch2.6.bias\n",
      "model.3.0.branch2.6.running_mean\n",
      "model.3.0.branch2.6.running_var\n",
      "model.3.0.branch2.6.num_batches_tracked\n",
      "model.3.1.branch2.0.weight\n",
      "model.3.1.branch2.1.weight\n",
      "model.3.1.branch2.1.bias\n",
      "model.3.1.branch2.1.running_mean\n",
      "model.3.1.branch2.1.running_var\n",
      "model.3.1.branch2.1.num_batches_tracked\n",
      "model.3.1.branch2.3.weight\n",
      "model.3.1.branch2.4.weight\n",
      "model.3.1.branch2.4.bias\n",
      "model.3.1.branch2.4.running_mean\n",
      "model.3.1.branch2.4.running_var\n",
      "model.3.1.branch2.4.num_batches_tracked\n",
      "model.3.1.branch2.5.weight\n",
      "model.3.1.branch2.6.weight\n",
      "model.3.1.branch2.6.bias\n",
      "model.3.1.branch2.6.running_mean\n",
      "model.3.1.branch2.6.running_var\n",
      "model.3.1.branch2.6.num_batches_tracked\n",
      "model.3.2.branch2.0.weight\n",
      "model.3.2.branch2.1.weight\n",
      "model.3.2.branch2.1.bias\n",
      "model.3.2.branch2.1.running_mean\n",
      "model.3.2.branch2.1.running_var\n",
      "model.3.2.branch2.1.num_batches_tracked\n",
      "model.3.2.branch2.3.weight\n",
      "model.3.2.branch2.4.weight\n",
      "model.3.2.branch2.4.bias\n",
      "model.3.2.branch2.4.running_mean\n",
      "model.3.2.branch2.4.running_var\n",
      "model.3.2.branch2.4.num_batches_tracked\n",
      "model.3.2.branch2.5.weight\n",
      "model.3.2.branch2.6.weight\n",
      "model.3.2.branch2.6.bias\n",
      "model.3.2.branch2.6.running_mean\n",
      "model.3.2.branch2.6.running_var\n",
      "model.3.2.branch2.6.num_batches_tracked\n",
      "model.4.0.branch1.0.weight\n",
      "model.4.0.branch1.1.weight\n",
      "model.4.0.branch1.1.bias\n",
      "model.4.0.branch1.1.running_mean\n",
      "model.4.0.branch1.1.running_var\n",
      "model.4.0.branch1.1.num_batches_tracked\n",
      "model.4.0.branch1.2.weight\n",
      "model.4.0.branch1.3.weight\n",
      "model.4.0.branch1.3.bias\n",
      "model.4.0.branch1.3.running_mean\n",
      "model.4.0.branch1.3.running_var\n",
      "model.4.0.branch1.3.num_batches_tracked\n",
      "model.4.0.branch2.0.weight\n",
      "model.4.0.branch2.1.weight\n",
      "model.4.0.branch2.1.bias\n",
      "model.4.0.branch2.1.running_mean\n",
      "model.4.0.branch2.1.running_var\n",
      "model.4.0.branch2.1.num_batches_tracked\n",
      "model.4.0.branch2.3.weight\n",
      "model.4.0.branch2.4.weight\n",
      "model.4.0.branch2.4.bias\n",
      "model.4.0.branch2.4.running_mean\n",
      "model.4.0.branch2.4.running_var\n",
      "model.4.0.branch2.4.num_batches_tracked\n",
      "model.4.0.branch2.5.weight\n",
      "model.4.0.branch2.6.weight\n",
      "model.4.0.branch2.6.bias\n",
      "model.4.0.branch2.6.running_mean\n",
      "model.4.0.branch2.6.running_var\n",
      "model.4.0.branch2.6.num_batches_tracked\n",
      "model.5.0.branch2.0.weight\n",
      "model.5.0.branch2.1.weight\n",
      "model.5.0.branch2.1.bias\n",
      "model.5.0.branch2.1.running_mean\n",
      "model.5.0.branch2.1.running_var\n",
      "model.5.0.branch2.1.num_batches_tracked\n",
      "model.5.0.branch2.3.weight\n",
      "model.5.0.branch2.4.weight\n",
      "model.5.0.branch2.4.bias\n",
      "model.5.0.branch2.4.running_mean\n",
      "model.5.0.branch2.4.running_var\n",
      "model.5.0.branch2.4.num_batches_tracked\n",
      "model.5.0.branch2.5.weight\n",
      "model.5.0.branch2.6.weight\n",
      "model.5.0.branch2.6.bias\n",
      "model.5.0.branch2.6.running_mean\n",
      "model.5.0.branch2.6.running_var\n",
      "model.5.0.branch2.6.num_batches_tracked\n",
      "model.5.1.branch2.0.weight\n",
      "model.5.1.branch2.1.weight\n",
      "model.5.1.branch2.1.bias\n",
      "model.5.1.branch2.1.running_mean\n",
      "model.5.1.branch2.1.running_var\n",
      "model.5.1.branch2.1.num_batches_tracked\n",
      "model.5.1.branch2.3.weight\n",
      "model.5.1.branch2.4.weight\n",
      "model.5.1.branch2.4.bias\n",
      "model.5.1.branch2.4.running_mean\n",
      "model.5.1.branch2.4.running_var\n",
      "model.5.1.branch2.4.num_batches_tracked\n",
      "model.5.1.branch2.5.weight\n",
      "model.5.1.branch2.6.weight\n",
      "model.5.1.branch2.6.bias\n",
      "model.5.1.branch2.6.running_mean\n",
      "model.5.1.branch2.6.running_var\n",
      "model.5.1.branch2.6.num_batches_tracked\n",
      "model.5.2.branch2.0.weight\n",
      "model.5.2.branch2.1.weight\n",
      "model.5.2.branch2.1.bias\n",
      "model.5.2.branch2.1.running_mean\n",
      "model.5.2.branch2.1.running_var\n",
      "model.5.2.branch2.1.num_batches_tracked\n",
      "model.5.2.branch2.3.weight\n",
      "model.5.2.branch2.4.weight\n",
      "model.5.2.branch2.4.bias\n",
      "model.5.2.branch2.4.running_mean\n",
      "model.5.2.branch2.4.running_var\n",
      "model.5.2.branch2.4.num_batches_tracked\n",
      "model.5.2.branch2.5.weight\n",
      "model.5.2.branch2.6.weight\n",
      "model.5.2.branch2.6.bias\n",
      "model.5.2.branch2.6.running_mean\n",
      "model.5.2.branch2.6.running_var\n",
      "model.5.2.branch2.6.num_batches_tracked\n",
      "model.5.3.branch2.0.weight\n",
      "model.5.3.branch2.1.weight\n",
      "model.5.3.branch2.1.bias\n",
      "model.5.3.branch2.1.running_mean\n",
      "model.5.3.branch2.1.running_var\n",
      "model.5.3.branch2.1.num_batches_tracked\n",
      "model.5.3.branch2.3.weight\n",
      "model.5.3.branch2.4.weight\n",
      "model.5.3.branch2.4.bias\n",
      "model.5.3.branch2.4.running_mean\n",
      "model.5.3.branch2.4.running_var\n",
      "model.5.3.branch2.4.num_batches_tracked\n",
      "model.5.3.branch2.5.weight\n",
      "model.5.3.branch2.6.weight\n",
      "model.5.3.branch2.6.bias\n",
      "model.5.3.branch2.6.running_mean\n",
      "model.5.3.branch2.6.running_var\n",
      "model.5.3.branch2.6.num_batches_tracked\n",
      "model.5.4.branch2.0.weight\n",
      "model.5.4.branch2.1.weight\n",
      "model.5.4.branch2.1.bias\n",
      "model.5.4.branch2.1.running_mean\n",
      "model.5.4.branch2.1.running_var\n",
      "model.5.4.branch2.1.num_batches_tracked\n",
      "model.5.4.branch2.3.weight\n",
      "model.5.4.branch2.4.weight\n",
      "model.5.4.branch2.4.bias\n",
      "model.5.4.branch2.4.running_mean\n",
      "model.5.4.branch2.4.running_var\n",
      "model.5.4.branch2.4.num_batches_tracked\n",
      "model.5.4.branch2.5.weight\n",
      "model.5.4.branch2.6.weight\n",
      "model.5.4.branch2.6.bias\n",
      "model.5.4.branch2.6.running_mean\n",
      "model.5.4.branch2.6.running_var\n",
      "model.5.4.branch2.6.num_batches_tracked\n",
      "model.5.5.branch2.0.weight\n",
      "model.5.5.branch2.1.weight\n",
      "model.5.5.branch2.1.bias\n",
      "model.5.5.branch2.1.running_mean\n",
      "model.5.5.branch2.1.running_var\n",
      "model.5.5.branch2.1.num_batches_tracked\n",
      "model.5.5.branch2.3.weight\n",
      "model.5.5.branch2.4.weight\n",
      "model.5.5.branch2.4.bias\n",
      "model.5.5.branch2.4.running_mean\n",
      "model.5.5.branch2.4.running_var\n",
      "model.5.5.branch2.4.num_batches_tracked\n",
      "model.5.5.branch2.5.weight\n",
      "model.5.5.branch2.6.weight\n",
      "model.5.5.branch2.6.bias\n",
      "model.5.5.branch2.6.running_mean\n",
      "model.5.5.branch2.6.running_var\n",
      "model.5.5.branch2.6.num_batches_tracked\n",
      "model.5.6.branch2.0.weight\n",
      "model.5.6.branch2.1.weight\n",
      "model.5.6.branch2.1.bias\n",
      "model.5.6.branch2.1.running_mean\n",
      "model.5.6.branch2.1.running_var\n",
      "model.5.6.branch2.1.num_batches_tracked\n",
      "model.5.6.branch2.3.weight\n",
      "model.5.6.branch2.4.weight\n",
      "model.5.6.branch2.4.bias\n",
      "model.5.6.branch2.4.running_mean\n",
      "model.5.6.branch2.4.running_var\n",
      "model.5.6.branch2.4.num_batches_tracked\n",
      "model.5.6.branch2.5.weight\n",
      "model.5.6.branch2.6.weight\n",
      "model.5.6.branch2.6.bias\n",
      "model.5.6.branch2.6.running_mean\n",
      "model.5.6.branch2.6.running_var\n",
      "model.5.6.branch2.6.num_batches_tracked\n",
      "model.6.0.branch1.0.weight\n",
      "model.6.0.branch1.1.weight\n",
      "model.6.0.branch1.1.bias\n",
      "model.6.0.branch1.1.running_mean\n",
      "model.6.0.branch1.1.running_var\n",
      "model.6.0.branch1.1.num_batches_tracked\n",
      "model.6.0.branch1.2.weight\n",
      "model.6.0.branch1.3.weight\n",
      "model.6.0.branch1.3.bias\n",
      "model.6.0.branch1.3.running_mean\n",
      "model.6.0.branch1.3.running_var\n",
      "model.6.0.branch1.3.num_batches_tracked\n",
      "model.6.0.branch2.0.weight\n",
      "model.6.0.branch2.1.weight\n",
      "model.6.0.branch2.1.bias\n",
      "model.6.0.branch2.1.running_mean\n",
      "model.6.0.branch2.1.running_var\n",
      "model.6.0.branch2.1.num_batches_tracked\n",
      "model.6.0.branch2.3.weight\n",
      "model.6.0.branch2.4.weight\n",
      "model.6.0.branch2.4.bias\n",
      "model.6.0.branch2.4.running_mean\n",
      "model.6.0.branch2.4.running_var\n",
      "model.6.0.branch2.4.num_batches_tracked\n",
      "model.6.0.branch2.5.weight\n",
      "model.6.0.branch2.6.weight\n",
      "model.6.0.branch2.6.bias\n",
      "model.6.0.branch2.6.running_mean\n",
      "model.6.0.branch2.6.running_var\n",
      "model.6.0.branch2.6.num_batches_tracked\n",
      "model.7.0.branch2.0.weight\n",
      "model.7.0.branch2.1.weight\n",
      "model.7.0.branch2.1.bias\n",
      "model.7.0.branch2.1.running_mean\n",
      "model.7.0.branch2.1.running_var\n",
      "model.7.0.branch2.1.num_batches_tracked\n",
      "model.7.0.branch2.3.weight\n",
      "model.7.0.branch2.4.weight\n",
      "model.7.0.branch2.4.bias\n",
      "model.7.0.branch2.4.running_mean\n",
      "model.7.0.branch2.4.running_var\n",
      "model.7.0.branch2.4.num_batches_tracked\n",
      "model.7.0.branch2.5.weight\n",
      "model.7.0.branch2.6.weight\n",
      "model.7.0.branch2.6.bias\n",
      "model.7.0.branch2.6.running_mean\n",
      "model.7.0.branch2.6.running_var\n",
      "model.7.0.branch2.6.num_batches_tracked\n",
      "model.7.1.branch2.0.weight\n",
      "model.7.1.branch2.1.weight\n",
      "model.7.1.branch2.1.bias\n",
      "model.7.1.branch2.1.running_mean\n",
      "model.7.1.branch2.1.running_var\n",
      "model.7.1.branch2.1.num_batches_tracked\n",
      "model.7.1.branch2.3.weight\n",
      "model.7.1.branch2.4.weight\n",
      "model.7.1.branch2.4.bias\n",
      "model.7.1.branch2.4.running_mean\n",
      "model.7.1.branch2.4.running_var\n",
      "model.7.1.branch2.4.num_batches_tracked\n",
      "model.7.1.branch2.5.weight\n",
      "model.7.1.branch2.6.weight\n",
      "model.7.1.branch2.6.bias\n",
      "model.7.1.branch2.6.running_mean\n",
      "model.7.1.branch2.6.running_var\n",
      "model.7.1.branch2.6.num_batches_tracked\n",
      "model.7.2.branch2.0.weight\n",
      "model.7.2.branch2.1.weight\n",
      "model.7.2.branch2.1.bias\n",
      "model.7.2.branch2.1.running_mean\n",
      "model.7.2.branch2.1.running_var\n",
      "model.7.2.branch2.1.num_batches_tracked\n",
      "model.7.2.branch2.3.weight\n",
      "model.7.2.branch2.4.weight\n",
      "model.7.2.branch2.4.bias\n",
      "model.7.2.branch2.4.running_mean\n",
      "model.7.2.branch2.4.running_var\n",
      "model.7.2.branch2.4.num_batches_tracked\n",
      "model.7.2.branch2.5.weight\n",
      "model.7.2.branch2.6.weight\n",
      "model.7.2.branch2.6.bias\n",
      "model.7.2.branch2.6.running_mean\n",
      "model.7.2.branch2.6.running_var\n",
      "model.7.2.branch2.6.num_batches_tracked\n",
      "model.8.conv.weight\n",
      "model.8.bn.weight\n",
      "model.8.bn.bias\n",
      "model.8.bn.running_mean\n",
      "model.8.bn.running_var\n",
      "model.8.bn.num_batches_tracked\n",
      "model.11.linear.weight\n",
      "model.11.linear.bias\n"
     ]
    }
   ],
   "source": [
    "print(*shufflenet_v2_05_base.state_dict().keys(), sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338\n"
     ]
    }
   ],
   "source": [
    "print(len(shufflenet_v2_05_base.state_dict()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model.conv1.0.weight': 'model.0.conv.weight', 'model.conv1.1.weight': 'model.0.bn.weight', 'model.conv1.1.bias': 'model.0.bn.bias', 'model.conv1.1.running_mean': 'model.0.bn.running_mean', 'model.conv1.1.running_var': 'model.0.bn.running_var', 'model.conv1.1.num_batches_tracked': 'model.0.bn.num_batches_tracked', 'model.stage2.0.branch1.0.weight': 'model.2.0.branch1.0.weight', 'model.stage2.0.branch1.1.weight': 'model.2.0.branch1.1.weight', 'model.stage2.0.branch1.1.bias': 'model.2.0.branch1.1.bias', 'model.stage2.0.branch1.1.running_mean': 'model.2.0.branch1.1.running_mean', 'model.stage2.0.branch1.1.running_var': 'model.2.0.branch1.1.running_var', 'model.stage2.0.branch1.1.num_batches_tracked': 'model.2.0.branch1.1.num_batches_tracked', 'model.stage2.0.branch1.2.weight': 'model.2.0.branch1.2.weight', 'model.stage2.0.branch1.3.weight': 'model.2.0.branch1.3.weight', 'model.stage2.0.branch1.3.bias': 'model.2.0.branch1.3.bias', 'model.stage2.0.branch1.3.running_mean': 'model.2.0.branch1.3.running_mean', 'model.stage2.0.branch1.3.running_var': 'model.2.0.branch1.3.running_var', 'model.stage2.0.branch1.3.num_batches_tracked': 'model.2.0.branch1.3.num_batches_tracked', 'model.stage2.0.branch2.0.weight': 'model.2.0.branch2.0.weight', 'model.stage2.0.branch2.1.weight': 'model.2.0.branch2.1.weight', 'model.stage2.0.branch2.1.bias': 'model.2.0.branch2.1.bias', 'model.stage2.0.branch2.1.running_mean': 'model.2.0.branch2.1.running_mean', 'model.stage2.0.branch2.1.running_var': 'model.2.0.branch2.1.running_var', 'model.stage2.0.branch2.1.num_batches_tracked': 'model.2.0.branch2.1.num_batches_tracked', 'model.stage2.0.branch2.3.weight': 'model.2.0.branch2.3.weight', 'model.stage2.0.branch2.4.weight': 'model.2.0.branch2.4.weight', 'model.stage2.0.branch2.4.bias': 'model.2.0.branch2.4.bias', 'model.stage2.0.branch2.4.running_mean': 'model.2.0.branch2.4.running_mean', 'model.stage2.0.branch2.4.running_var': 'model.2.0.branch2.4.running_var', 'model.stage2.0.branch2.4.num_batches_tracked': 'model.2.0.branch2.4.num_batches_tracked', 'model.stage2.0.branch2.5.weight': 'model.2.0.branch2.5.weight', 'model.stage2.0.branch2.6.weight': 'model.2.0.branch2.6.weight', 'model.stage2.0.branch2.6.bias': 'model.2.0.branch2.6.bias', 'model.stage2.0.branch2.6.running_mean': 'model.2.0.branch2.6.running_mean', 'model.stage2.0.branch2.6.running_var': 'model.2.0.branch2.6.running_var', 'model.stage2.0.branch2.6.num_batches_tracked': 'model.2.0.branch2.6.num_batches_tracked', 'model.stage2.1.branch2.0.weight': 'model.3.0.branch2.0.weight', 'model.stage2.1.branch2.1.weight': 'model.3.0.branch2.1.weight', 'model.stage2.1.branch2.1.bias': 'model.3.0.branch2.1.bias', 'model.stage2.1.branch2.1.running_mean': 'model.3.0.branch2.1.running_mean', 'model.stage2.1.branch2.1.running_var': 'model.3.0.branch2.1.running_var', 'model.stage2.1.branch2.1.num_batches_tracked': 'model.3.0.branch2.1.num_batches_tracked', 'model.stage2.1.branch2.3.weight': 'model.3.0.branch2.3.weight', 'model.stage2.1.branch2.4.weight': 'model.3.0.branch2.4.weight', 'model.stage2.1.branch2.4.bias': 'model.3.0.branch2.4.bias', 'model.stage2.1.branch2.4.running_mean': 'model.3.0.branch2.4.running_mean', 'model.stage2.1.branch2.4.running_var': 'model.3.0.branch2.4.running_var', 'model.stage2.1.branch2.4.num_batches_tracked': 'model.3.0.branch2.4.num_batches_tracked', 'model.stage2.1.branch2.5.weight': 'model.3.0.branch2.5.weight', 'model.stage2.1.branch2.6.weight': 'model.3.0.branch2.6.weight', 'model.stage2.1.branch2.6.bias': 'model.3.0.branch2.6.bias', 'model.stage2.1.branch2.6.running_mean': 'model.3.0.branch2.6.running_mean', 'model.stage2.1.branch2.6.running_var': 'model.3.0.branch2.6.running_var', 'model.stage2.1.branch2.6.num_batches_tracked': 'model.3.0.branch2.6.num_batches_tracked', 'model.stage2.2.branch2.0.weight': 'model.3.1.branch2.0.weight', 'model.stage2.2.branch2.1.weight': 'model.3.1.branch2.1.weight', 'model.stage2.2.branch2.1.bias': 'model.3.1.branch2.1.bias', 'model.stage2.2.branch2.1.running_mean': 'model.3.1.branch2.1.running_mean', 'model.stage2.2.branch2.1.running_var': 'model.3.1.branch2.1.running_var', 'model.stage2.2.branch2.1.num_batches_tracked': 'model.3.1.branch2.1.num_batches_tracked', 'model.stage2.2.branch2.3.weight': 'model.3.1.branch2.3.weight', 'model.stage2.2.branch2.4.weight': 'model.3.1.branch2.4.weight', 'model.stage2.2.branch2.4.bias': 'model.3.1.branch2.4.bias', 'model.stage2.2.branch2.4.running_mean': 'model.3.1.branch2.4.running_mean', 'model.stage2.2.branch2.4.running_var': 'model.3.1.branch2.4.running_var', 'model.stage2.2.branch2.4.num_batches_tracked': 'model.3.1.branch2.4.num_batches_tracked', 'model.stage2.2.branch2.5.weight': 'model.3.1.branch2.5.weight', 'model.stage2.2.branch2.6.weight': 'model.3.1.branch2.6.weight', 'model.stage2.2.branch2.6.bias': 'model.3.1.branch2.6.bias', 'model.stage2.2.branch2.6.running_mean': 'model.3.1.branch2.6.running_mean', 'model.stage2.2.branch2.6.running_var': 'model.3.1.branch2.6.running_var', 'model.stage2.2.branch2.6.num_batches_tracked': 'model.3.1.branch2.6.num_batches_tracked', 'model.stage2.3.branch2.0.weight': 'model.3.2.branch2.0.weight', 'model.stage2.3.branch2.1.weight': 'model.3.2.branch2.1.weight', 'model.stage2.3.branch2.1.bias': 'model.3.2.branch2.1.bias', 'model.stage2.3.branch2.1.running_mean': 'model.3.2.branch2.1.running_mean', 'model.stage2.3.branch2.1.running_var': 'model.3.2.branch2.1.running_var', 'model.stage2.3.branch2.1.num_batches_tracked': 'model.3.2.branch2.1.num_batches_tracked', 'model.stage2.3.branch2.3.weight': 'model.3.2.branch2.3.weight', 'model.stage2.3.branch2.4.weight': 'model.3.2.branch2.4.weight', 'model.stage2.3.branch2.4.bias': 'model.3.2.branch2.4.bias', 'model.stage2.3.branch2.4.running_mean': 'model.3.2.branch2.4.running_mean', 'model.stage2.3.branch2.4.running_var': 'model.3.2.branch2.4.running_var', 'model.stage2.3.branch2.4.num_batches_tracked': 'model.3.2.branch2.4.num_batches_tracked', 'model.stage2.3.branch2.5.weight': 'model.3.2.branch2.5.weight', 'model.stage2.3.branch2.6.weight': 'model.3.2.branch2.6.weight', 'model.stage2.3.branch2.6.bias': 'model.3.2.branch2.6.bias', 'model.stage2.3.branch2.6.running_mean': 'model.3.2.branch2.6.running_mean', 'model.stage2.3.branch2.6.running_var': 'model.3.2.branch2.6.running_var', 'model.stage2.3.branch2.6.num_batches_tracked': 'model.3.2.branch2.6.num_batches_tracked', 'model.stage3.0.branch1.0.weight': 'model.4.0.branch1.0.weight', 'model.stage3.0.branch1.1.weight': 'model.4.0.branch1.1.weight', 'model.stage3.0.branch1.1.bias': 'model.4.0.branch1.1.bias', 'model.stage3.0.branch1.1.running_mean': 'model.4.0.branch1.1.running_mean', 'model.stage3.0.branch1.1.running_var': 'model.4.0.branch1.1.running_var', 'model.stage3.0.branch1.1.num_batches_tracked': 'model.4.0.branch1.1.num_batches_tracked', 'model.stage3.0.branch1.2.weight': 'model.4.0.branch1.2.weight', 'model.stage3.0.branch1.3.weight': 'model.4.0.branch1.3.weight', 'model.stage3.0.branch1.3.bias': 'model.4.0.branch1.3.bias', 'model.stage3.0.branch1.3.running_mean': 'model.4.0.branch1.3.running_mean', 'model.stage3.0.branch1.3.running_var': 'model.4.0.branch1.3.running_var', 'model.stage3.0.branch1.3.num_batches_tracked': 'model.4.0.branch1.3.num_batches_tracked', 'model.stage3.0.branch2.0.weight': 'model.4.0.branch2.0.weight', 'model.stage3.0.branch2.1.weight': 'model.4.0.branch2.1.weight', 'model.stage3.0.branch2.1.bias': 'model.4.0.branch2.1.bias', 'model.stage3.0.branch2.1.running_mean': 'model.4.0.branch2.1.running_mean', 'model.stage3.0.branch2.1.running_var': 'model.4.0.branch2.1.running_var', 'model.stage3.0.branch2.1.num_batches_tracked': 'model.4.0.branch2.1.num_batches_tracked', 'model.stage3.0.branch2.3.weight': 'model.4.0.branch2.3.weight', 'model.stage3.0.branch2.4.weight': 'model.4.0.branch2.4.weight', 'model.stage3.0.branch2.4.bias': 'model.4.0.branch2.4.bias', 'model.stage3.0.branch2.4.running_mean': 'model.4.0.branch2.4.running_mean', 'model.stage3.0.branch2.4.running_var': 'model.4.0.branch2.4.running_var', 'model.stage3.0.branch2.4.num_batches_tracked': 'model.4.0.branch2.4.num_batches_tracked', 'model.stage3.0.branch2.5.weight': 'model.4.0.branch2.5.weight', 'model.stage3.0.branch2.6.weight': 'model.4.0.branch2.6.weight', 'model.stage3.0.branch2.6.bias': 'model.4.0.branch2.6.bias', 'model.stage3.0.branch2.6.running_mean': 'model.4.0.branch2.6.running_mean', 'model.stage3.0.branch2.6.running_var': 'model.4.0.branch2.6.running_var', 'model.stage3.0.branch2.6.num_batches_tracked': 'model.4.0.branch2.6.num_batches_tracked', 'model.stage3.1.branch2.0.weight': 'model.5.0.branch2.0.weight', 'model.stage3.1.branch2.1.weight': 'model.5.0.branch2.1.weight', 'model.stage3.1.branch2.1.bias': 'model.5.0.branch2.1.bias', 'model.stage3.1.branch2.1.running_mean': 'model.5.0.branch2.1.running_mean', 'model.stage3.1.branch2.1.running_var': 'model.5.0.branch2.1.running_var', 'model.stage3.1.branch2.1.num_batches_tracked': 'model.5.0.branch2.1.num_batches_tracked', 'model.stage3.1.branch2.3.weight': 'model.5.0.branch2.3.weight', 'model.stage3.1.branch2.4.weight': 'model.5.0.branch2.4.weight', 'model.stage3.1.branch2.4.bias': 'model.5.0.branch2.4.bias', 'model.stage3.1.branch2.4.running_mean': 'model.5.0.branch2.4.running_mean', 'model.stage3.1.branch2.4.running_var': 'model.5.0.branch2.4.running_var', 'model.stage3.1.branch2.4.num_batches_tracked': 'model.5.0.branch2.4.num_batches_tracked', 'model.stage3.1.branch2.5.weight': 'model.5.0.branch2.5.weight', 'model.stage3.1.branch2.6.weight': 'model.5.0.branch2.6.weight', 'model.stage3.1.branch2.6.bias': 'model.5.0.branch2.6.bias', 'model.stage3.1.branch2.6.running_mean': 'model.5.0.branch2.6.running_mean', 'model.stage3.1.branch2.6.running_var': 'model.5.0.branch2.6.running_var', 'model.stage3.1.branch2.6.num_batches_tracked': 'model.5.0.branch2.6.num_batches_tracked', 'model.stage3.2.branch2.0.weight': 'model.5.1.branch2.0.weight', 'model.stage3.2.branch2.1.weight': 'model.5.1.branch2.1.weight', 'model.stage3.2.branch2.1.bias': 'model.5.1.branch2.1.bias', 'model.stage3.2.branch2.1.running_mean': 'model.5.1.branch2.1.running_mean', 'model.stage3.2.branch2.1.running_var': 'model.5.1.branch2.1.running_var', 'model.stage3.2.branch2.1.num_batches_tracked': 'model.5.1.branch2.1.num_batches_tracked', 'model.stage3.2.branch2.3.weight': 'model.5.1.branch2.3.weight', 'model.stage3.2.branch2.4.weight': 'model.5.1.branch2.4.weight', 'model.stage3.2.branch2.4.bias': 'model.5.1.branch2.4.bias', 'model.stage3.2.branch2.4.running_mean': 'model.5.1.branch2.4.running_mean', 'model.stage3.2.branch2.4.running_var': 'model.5.1.branch2.4.running_var', 'model.stage3.2.branch2.4.num_batches_tracked': 'model.5.1.branch2.4.num_batches_tracked', 'model.stage3.2.branch2.5.weight': 'model.5.1.branch2.5.weight', 'model.stage3.2.branch2.6.weight': 'model.5.1.branch2.6.weight', 'model.stage3.2.branch2.6.bias': 'model.5.1.branch2.6.bias', 'model.stage3.2.branch2.6.running_mean': 'model.5.1.branch2.6.running_mean', 'model.stage3.2.branch2.6.running_var': 'model.5.1.branch2.6.running_var', 'model.stage3.2.branch2.6.num_batches_tracked': 'model.5.1.branch2.6.num_batches_tracked', 'model.stage3.3.branch2.0.weight': 'model.5.2.branch2.0.weight', 'model.stage3.3.branch2.1.weight': 'model.5.2.branch2.1.weight', 'model.stage3.3.branch2.1.bias': 'model.5.2.branch2.1.bias', 'model.stage3.3.branch2.1.running_mean': 'model.5.2.branch2.1.running_mean', 'model.stage3.3.branch2.1.running_var': 'model.5.2.branch2.1.running_var', 'model.stage3.3.branch2.1.num_batches_tracked': 'model.5.2.branch2.1.num_batches_tracked', 'model.stage3.3.branch2.3.weight': 'model.5.2.branch2.3.weight', 'model.stage3.3.branch2.4.weight': 'model.5.2.branch2.4.weight', 'model.stage3.3.branch2.4.bias': 'model.5.2.branch2.4.bias', 'model.stage3.3.branch2.4.running_mean': 'model.5.2.branch2.4.running_mean', 'model.stage3.3.branch2.4.running_var': 'model.5.2.branch2.4.running_var', 'model.stage3.3.branch2.4.num_batches_tracked': 'model.5.2.branch2.4.num_batches_tracked', 'model.stage3.3.branch2.5.weight': 'model.5.2.branch2.5.weight', 'model.stage3.3.branch2.6.weight': 'model.5.2.branch2.6.weight', 'model.stage3.3.branch2.6.bias': 'model.5.2.branch2.6.bias', 'model.stage3.3.branch2.6.running_mean': 'model.5.2.branch2.6.running_mean', 'model.stage3.3.branch2.6.running_var': 'model.5.2.branch2.6.running_var', 'model.stage3.3.branch2.6.num_batches_tracked': 'model.5.2.branch2.6.num_batches_tracked', 'model.stage3.4.branch2.0.weight': 'model.5.3.branch2.0.weight', 'model.stage3.4.branch2.1.weight': 'model.5.3.branch2.1.weight', 'model.stage3.4.branch2.1.bias': 'model.5.3.branch2.1.bias', 'model.stage3.4.branch2.1.running_mean': 'model.5.3.branch2.1.running_mean', 'model.stage3.4.branch2.1.running_var': 'model.5.3.branch2.1.running_var', 'model.stage3.4.branch2.1.num_batches_tracked': 'model.5.3.branch2.1.num_batches_tracked', 'model.stage3.4.branch2.3.weight': 'model.5.3.branch2.3.weight', 'model.stage3.4.branch2.4.weight': 'model.5.3.branch2.4.weight', 'model.stage3.4.branch2.4.bias': 'model.5.3.branch2.4.bias', 'model.stage3.4.branch2.4.running_mean': 'model.5.3.branch2.4.running_mean', 'model.stage3.4.branch2.4.running_var': 'model.5.3.branch2.4.running_var', 'model.stage3.4.branch2.4.num_batches_tracked': 'model.5.3.branch2.4.num_batches_tracked', 'model.stage3.4.branch2.5.weight': 'model.5.3.branch2.5.weight', 'model.stage3.4.branch2.6.weight': 'model.5.3.branch2.6.weight', 'model.stage3.4.branch2.6.bias': 'model.5.3.branch2.6.bias', 'model.stage3.4.branch2.6.running_mean': 'model.5.3.branch2.6.running_mean', 'model.stage3.4.branch2.6.running_var': 'model.5.3.branch2.6.running_var', 'model.stage3.4.branch2.6.num_batches_tracked': 'model.5.3.branch2.6.num_batches_tracked', 'model.stage3.5.branch2.0.weight': 'model.5.4.branch2.0.weight', 'model.stage3.5.branch2.1.weight': 'model.5.4.branch2.1.weight', 'model.stage3.5.branch2.1.bias': 'model.5.4.branch2.1.bias', 'model.stage3.5.branch2.1.running_mean': 'model.5.4.branch2.1.running_mean', 'model.stage3.5.branch2.1.running_var': 'model.5.4.branch2.1.running_var', 'model.stage3.5.branch2.1.num_batches_tracked': 'model.5.4.branch2.1.num_batches_tracked', 'model.stage3.5.branch2.3.weight': 'model.5.4.branch2.3.weight', 'model.stage3.5.branch2.4.weight': 'model.5.4.branch2.4.weight', 'model.stage3.5.branch2.4.bias': 'model.5.4.branch2.4.bias', 'model.stage3.5.branch2.4.running_mean': 'model.5.4.branch2.4.running_mean', 'model.stage3.5.branch2.4.running_var': 'model.5.4.branch2.4.running_var', 'model.stage3.5.branch2.4.num_batches_tracked': 'model.5.4.branch2.4.num_batches_tracked', 'model.stage3.5.branch2.5.weight': 'model.5.4.branch2.5.weight', 'model.stage3.5.branch2.6.weight': 'model.5.4.branch2.6.weight', 'model.stage3.5.branch2.6.bias': 'model.5.4.branch2.6.bias', 'model.stage3.5.branch2.6.running_mean': 'model.5.4.branch2.6.running_mean', 'model.stage3.5.branch2.6.running_var': 'model.5.4.branch2.6.running_var', 'model.stage3.5.branch2.6.num_batches_tracked': 'model.5.4.branch2.6.num_batches_tracked', 'model.stage3.6.branch2.0.weight': 'model.5.5.branch2.0.weight', 'model.stage3.6.branch2.1.weight': 'model.5.5.branch2.1.weight', 'model.stage3.6.branch2.1.bias': 'model.5.5.branch2.1.bias', 'model.stage3.6.branch2.1.running_mean': 'model.5.5.branch2.1.running_mean', 'model.stage3.6.branch2.1.running_var': 'model.5.5.branch2.1.running_var', 'model.stage3.6.branch2.1.num_batches_tracked': 'model.5.5.branch2.1.num_batches_tracked', 'model.stage3.6.branch2.3.weight': 'model.5.5.branch2.3.weight', 'model.stage3.6.branch2.4.weight': 'model.5.5.branch2.4.weight', 'model.stage3.6.branch2.4.bias': 'model.5.5.branch2.4.bias', 'model.stage3.6.branch2.4.running_mean': 'model.5.5.branch2.4.running_mean', 'model.stage3.6.branch2.4.running_var': 'model.5.5.branch2.4.running_var', 'model.stage3.6.branch2.4.num_batches_tracked': 'model.5.5.branch2.4.num_batches_tracked', 'model.stage3.6.branch2.5.weight': 'model.5.5.branch2.5.weight', 'model.stage3.6.branch2.6.weight': 'model.5.5.branch2.6.weight', 'model.stage3.6.branch2.6.bias': 'model.5.5.branch2.6.bias', 'model.stage3.6.branch2.6.running_mean': 'model.5.5.branch2.6.running_mean', 'model.stage3.6.branch2.6.running_var': 'model.5.5.branch2.6.running_var', 'model.stage3.6.branch2.6.num_batches_tracked': 'model.5.5.branch2.6.num_batches_tracked', 'model.stage3.7.branch2.0.weight': 'model.5.6.branch2.0.weight', 'model.stage3.7.branch2.1.weight': 'model.5.6.branch2.1.weight', 'model.stage3.7.branch2.1.bias': 'model.5.6.branch2.1.bias', 'model.stage3.7.branch2.1.running_mean': 'model.5.6.branch2.1.running_mean', 'model.stage3.7.branch2.1.running_var': 'model.5.6.branch2.1.running_var', 'model.stage3.7.branch2.1.num_batches_tracked': 'model.5.6.branch2.1.num_batches_tracked', 'model.stage3.7.branch2.3.weight': 'model.5.6.branch2.3.weight', 'model.stage3.7.branch2.4.weight': 'model.5.6.branch2.4.weight', 'model.stage3.7.branch2.4.bias': 'model.5.6.branch2.4.bias', 'model.stage3.7.branch2.4.running_mean': 'model.5.6.branch2.4.running_mean', 'model.stage3.7.branch2.4.running_var': 'model.5.6.branch2.4.running_var', 'model.stage3.7.branch2.4.num_batches_tracked': 'model.5.6.branch2.4.num_batches_tracked', 'model.stage3.7.branch2.5.weight': 'model.5.6.branch2.5.weight', 'model.stage3.7.branch2.6.weight': 'model.5.6.branch2.6.weight', 'model.stage3.7.branch2.6.bias': 'model.5.6.branch2.6.bias', 'model.stage3.7.branch2.6.running_mean': 'model.5.6.branch2.6.running_mean', 'model.stage3.7.branch2.6.running_var': 'model.5.6.branch2.6.running_var', 'model.stage3.7.branch2.6.num_batches_tracked': 'model.5.6.branch2.6.num_batches_tracked', 'model.stage4.0.branch1.0.weight': 'model.6.0.branch1.0.weight', 'model.stage4.0.branch1.1.weight': 'model.6.0.branch1.1.weight', 'model.stage4.0.branch1.1.bias': 'model.6.0.branch1.1.bias', 'model.stage4.0.branch1.1.running_mean': 'model.6.0.branch1.1.running_mean', 'model.stage4.0.branch1.1.running_var': 'model.6.0.branch1.1.running_var', 'model.stage4.0.branch1.1.num_batches_tracked': 'model.6.0.branch1.1.num_batches_tracked', 'model.stage4.0.branch1.2.weight': 'model.6.0.branch1.2.weight', 'model.stage4.0.branch1.3.weight': 'model.6.0.branch1.3.weight', 'model.stage4.0.branch1.3.bias': 'model.6.0.branch1.3.bias', 'model.stage4.0.branch1.3.running_mean': 'model.6.0.branch1.3.running_mean', 'model.stage4.0.branch1.3.running_var': 'model.6.0.branch1.3.running_var', 'model.stage4.0.branch1.3.num_batches_tracked': 'model.6.0.branch1.3.num_batches_tracked', 'model.stage4.0.branch2.0.weight': 'model.6.0.branch2.0.weight', 'model.stage4.0.branch2.1.weight': 'model.6.0.branch2.1.weight', 'model.stage4.0.branch2.1.bias': 'model.6.0.branch2.1.bias', 'model.stage4.0.branch2.1.running_mean': 'model.6.0.branch2.1.running_mean', 'model.stage4.0.branch2.1.running_var': 'model.6.0.branch2.1.running_var', 'model.stage4.0.branch2.1.num_batches_tracked': 'model.6.0.branch2.1.num_batches_tracked', 'model.stage4.0.branch2.3.weight': 'model.6.0.branch2.3.weight', 'model.stage4.0.branch2.4.weight': 'model.6.0.branch2.4.weight', 'model.stage4.0.branch2.4.bias': 'model.6.0.branch2.4.bias', 'model.stage4.0.branch2.4.running_mean': 'model.6.0.branch2.4.running_mean', 'model.stage4.0.branch2.4.running_var': 'model.6.0.branch2.4.running_var', 'model.stage4.0.branch2.4.num_batches_tracked': 'model.6.0.branch2.4.num_batches_tracked', 'model.stage4.0.branch2.5.weight': 'model.6.0.branch2.5.weight', 'model.stage4.0.branch2.6.weight': 'model.6.0.branch2.6.weight', 'model.stage4.0.branch2.6.bias': 'model.6.0.branch2.6.bias', 'model.stage4.0.branch2.6.running_mean': 'model.6.0.branch2.6.running_mean', 'model.stage4.0.branch2.6.running_var': 'model.6.0.branch2.6.running_var', 'model.stage4.0.branch2.6.num_batches_tracked': 'model.6.0.branch2.6.num_batches_tracked', 'model.stage4.1.branch2.0.weight': 'model.7.0.branch2.0.weight', 'model.stage4.1.branch2.1.weight': 'model.7.0.branch2.1.weight', 'model.stage4.1.branch2.1.bias': 'model.7.0.branch2.1.bias', 'model.stage4.1.branch2.1.running_mean': 'model.7.0.branch2.1.running_mean', 'model.stage4.1.branch2.1.running_var': 'model.7.0.branch2.1.running_var', 'model.stage4.1.branch2.1.num_batches_tracked': 'model.7.0.branch2.1.num_batches_tracked', 'model.stage4.1.branch2.3.weight': 'model.7.0.branch2.3.weight', 'model.stage4.1.branch2.4.weight': 'model.7.0.branch2.4.weight', 'model.stage4.1.branch2.4.bias': 'model.7.0.branch2.4.bias', 'model.stage4.1.branch2.4.running_mean': 'model.7.0.branch2.4.running_mean', 'model.stage4.1.branch2.4.running_var': 'model.7.0.branch2.4.running_var', 'model.stage4.1.branch2.4.num_batches_tracked': 'model.7.0.branch2.4.num_batches_tracked', 'model.stage4.1.branch2.5.weight': 'model.7.0.branch2.5.weight', 'model.stage4.1.branch2.6.weight': 'model.7.0.branch2.6.weight', 'model.stage4.1.branch2.6.bias': 'model.7.0.branch2.6.bias', 'model.stage4.1.branch2.6.running_mean': 'model.7.0.branch2.6.running_mean', 'model.stage4.1.branch2.6.running_var': 'model.7.0.branch2.6.running_var', 'model.stage4.1.branch2.6.num_batches_tracked': 'model.7.0.branch2.6.num_batches_tracked', 'model.stage4.2.branch2.0.weight': 'model.7.1.branch2.0.weight', 'model.stage4.2.branch2.1.weight': 'model.7.1.branch2.1.weight', 'model.stage4.2.branch2.1.bias': 'model.7.1.branch2.1.bias', 'model.stage4.2.branch2.1.running_mean': 'model.7.1.branch2.1.running_mean', 'model.stage4.2.branch2.1.running_var': 'model.7.1.branch2.1.running_var', 'model.stage4.2.branch2.1.num_batches_tracked': 'model.7.1.branch2.1.num_batches_tracked', 'model.stage4.2.branch2.3.weight': 'model.7.1.branch2.3.weight', 'model.stage4.2.branch2.4.weight': 'model.7.1.branch2.4.weight', 'model.stage4.2.branch2.4.bias': 'model.7.1.branch2.4.bias', 'model.stage4.2.branch2.4.running_mean': 'model.7.1.branch2.4.running_mean', 'model.stage4.2.branch2.4.running_var': 'model.7.1.branch2.4.running_var', 'model.stage4.2.branch2.4.num_batches_tracked': 'model.7.1.branch2.4.num_batches_tracked', 'model.stage4.2.branch2.5.weight': 'model.7.1.branch2.5.weight', 'model.stage4.2.branch2.6.weight': 'model.7.1.branch2.6.weight', 'model.stage4.2.branch2.6.bias': 'model.7.1.branch2.6.bias', 'model.stage4.2.branch2.6.running_mean': 'model.7.1.branch2.6.running_mean', 'model.stage4.2.branch2.6.running_var': 'model.7.1.branch2.6.running_var', 'model.stage4.2.branch2.6.num_batches_tracked': 'model.7.1.branch2.6.num_batches_tracked', 'model.stage4.3.branch2.0.weight': 'model.7.2.branch2.0.weight', 'model.stage4.3.branch2.1.weight': 'model.7.2.branch2.1.weight', 'model.stage4.3.branch2.1.bias': 'model.7.2.branch2.1.bias', 'model.stage4.3.branch2.1.running_mean': 'model.7.2.branch2.1.running_mean', 'model.stage4.3.branch2.1.running_var': 'model.7.2.branch2.1.running_var', 'model.stage4.3.branch2.1.num_batches_tracked': 'model.7.2.branch2.1.num_batches_tracked', 'model.stage4.3.branch2.3.weight': 'model.7.2.branch2.3.weight', 'model.stage4.3.branch2.4.weight': 'model.7.2.branch2.4.weight', 'model.stage4.3.branch2.4.bias': 'model.7.2.branch2.4.bias', 'model.stage4.3.branch2.4.running_mean': 'model.7.2.branch2.4.running_mean', 'model.stage4.3.branch2.4.running_var': 'model.7.2.branch2.4.running_var', 'model.stage4.3.branch2.4.num_batches_tracked': 'model.7.2.branch2.4.num_batches_tracked', 'model.stage4.3.branch2.5.weight': 'model.7.2.branch2.5.weight', 'model.stage4.3.branch2.6.weight': 'model.7.2.branch2.6.weight', 'model.stage4.3.branch2.6.bias': 'model.7.2.branch2.6.bias', 'model.stage4.3.branch2.6.running_mean': 'model.7.2.branch2.6.running_mean', 'model.stage4.3.branch2.6.running_var': 'model.7.2.branch2.6.running_var', 'model.stage4.3.branch2.6.num_batches_tracked': 'model.7.2.branch2.6.num_batches_tracked', 'model.conv5.0.weight': 'model.8.conv.weight', 'model.conv5.1.weight': 'model.8.bn.weight', 'model.conv5.1.bias': 'model.8.bn.bias', 'model.conv5.1.running_mean': 'model.8.bn.running_mean', 'model.conv5.1.running_var': 'model.8.bn.running_var', 'model.conv5.1.num_batches_tracked': 'model.8.bn.num_batches_tracked', 'model.fc.weight': 'model.11.linear.weight', 'model.fc.bias': 'model.11.linear.bias'}\n",
      "load_state_dict completed.\n"
     ]
    }
   ],
   "source": [
    "pretrained_state_dict = ShModel.state_dict()\n",
    "keys_load = [x for x in pretrained_state_dict.keys()]\n",
    "keys_load = {x:y for x,y in zip(keys_load, shufflenet_v2_05_base.state_dict().keys())}\n",
    "for before, after in keys_load.items():\n",
    "    pretrained_state_dict[after] = pretrained_state_dict.pop(before)\n",
    "print(keys_load)\n",
    "shufflenet_v2_05_base.load_state_dict(pretrained_state_dict)\n",
    "print(\"load_state_dict completed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "Model(\n  (model): Sequential(\n    (0): Conv(\n      (conv): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=[1], bias=False)\n      (bn): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act): ReLU()\n    )\n    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (2): Sequential(\n      (0): InvertedResidual(\n        (branch1): Sequential(\n          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (4): ReLU(inplace=True)\n        )\n        (branch2): Sequential(\n          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)\n          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n    )\n    (3): Sequential(\n      (0): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (1): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (2): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n    )\n    (4): Sequential(\n      (0): InvertedResidual(\n        (branch1): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (4): ReLU(inplace=True)\n        )\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n    )\n    (5): Sequential(\n      (0): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (1): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (2): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (3): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (4): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (5): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (6): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n          (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n    )\n    (6): Sequential(\n      (0): InvertedResidual(\n        (branch1): Sequential(\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (4): ReLU(inplace=True)\n        )\n        (branch2): Sequential(\n          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n    )\n    (7): Sequential(\n      (0): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (1): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n      (2): InvertedResidual(\n        (branch1): Sequential()\n        (branch2): Sequential(\n          (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n          (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (6): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (7): ReLU(inplace=True)\n        )\n      )\n    )\n    (8): Conv(\n      (conv): Conv2d(192, 1024, kernel_size=(1, 1), stride=(1, 1), padding=[0], bias=False)\n      (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (act): ReLU()\n    )\n    (9): GlobalAvgPool(output_size=1)\n    (10): Flatten(start_dim=1, end_dim=-1)\n    (11): Linear(\n      (linear): Linear(in_features=1024, out_features=9, bias=True)\n      (activation): Identity()\n    )\n  )\n)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "shufflenet_v2_05_base.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path: exptest/best.pt\n",
      "macs: 41810537.0\n",
      "Model saved. Current best test f1: 0.345\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.346\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.429\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.546\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.549\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.580\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.612\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.623\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.640\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.666\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.686\n",
      "Failed to save torch\n",
      "Model saved. Current best test f1: 0.693\n",
      "Failed to save torch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "  0%|          | 0/382 [00:00<?, ?it/s]/miniconda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Train: [001] Loss: 1.604, Acc: 45.11% F1(macro): 0.19: 100%|| 382/382 [02:55<00:00,  2.17it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 1.200, Acc: 58.06% F1(macro): 0.34: 100%|| 128/128 [00:53<00:00,  2.38it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [002] Loss: 1.313, Acc: 54.20% F1(macro): 0.34: 100%|| 382/382 [02:57<00:00,  2.16it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 1.268, Acc: 55.88% F1(macro): 0.35: 100%|| 128/128 [00:53<00:00,  2.40it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [003] Loss: 1.234, Acc: 56.95% F1(macro): 0.40: 100%|| 382/382 [02:55<00:00,  2.17it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 1.106, Acc: 61.02% F1(macro): 0.43: 100%|| 128/128 [00:55<00:00,  2.33it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [004] Loss: 1.185, Acc: 58.54% F1(macro): 0.43: 100%|| 382/382 [03:01<00:00,  2.10it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 1.028, Acc: 64.26% F1(macro): 0.55: 100%|| 128/128 [00:55<00:00,  2.31it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [005] Loss: 1.158, Acc: 59.42% F1(macro): 0.45: 100%|| 382/382 [03:05<00:00,  2.06it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 1.029, Acc: 63.40% F1(macro): 0.55: 100%|| 128/128 [00:54<00:00,  2.33it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [006] Loss: 1.128, Acc: 60.49% F1(macro): 0.48: 100%|| 382/382 [03:03<00:00,  2.08it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.986, Acc: 66.45% F1(macro): 0.58: 100%|| 128/128 [00:55<00:00,  2.32it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [007] Loss: 1.095, Acc: 61.13% F1(macro): 0.50: 100%|| 382/382 [03:05<00:00,  2.06it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.913, Acc: 67.19% F1(macro): 0.58: 100%|| 128/128 [00:55<00:00,  2.29it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [008] Loss: 1.069, Acc: 62.30% F1(macro): 0.52: 100%|| 382/382 [03:05<00:00,  2.06it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.914, Acc: 67.87% F1(macro): 0.61: 100%|| 128/128 [00:55<00:00,  2.31it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [009] Loss: 1.040, Acc: 63.74% F1(macro): 0.54: 100%|| 382/382 [03:04<00:00,  2.07it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.916, Acc: 68.10% F1(macro): 0.61: 100%|| 128/128 [00:55<00:00,  2.32it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [010] Loss: 1.006, Acc: 64.42% F1(macro): 0.55: 100%|| 382/382 [03:05<00:00,  2.06it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.883, Acc: 69.38% F1(macro): 0.62: 100%|| 128/128 [00:55<00:00,  2.31it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [011] Loss: 0.980, Acc: 65.74% F1(macro): 0.58: 100%|| 382/382 [03:04<00:00,  2.07it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.847, Acc: 70.72% F1(macro): 0.64: 100%|| 128/128 [00:55<00:00,  2.29it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [012] Loss: 0.938, Acc: 67.22% F1(macro): 0.60: 100%|| 382/382 [03:05<00:00,  2.06it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.811, Acc: 71.93% F1(macro): 0.67: 100%|| 128/128 [00:54<00:00,  2.36it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [013] Loss: 0.901, Acc: 68.57% F1(macro): 0.62: 100%|| 382/382 [03:04<00:00,  2.07it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.768, Acc: 73.71% F1(macro): 0.69: 100%|| 128/128 [00:55<00:00,  2.31it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [014] Loss: 0.870, Acc: 69.69% F1(macro): 0.63: 100%|| 382/382 [03:03<00:00,  2.08it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.755, Acc: 74.23% F1(macro): 0.69: 100%|| 128/128 [00:55<00:00,  2.30it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Train: [015] Loss: 0.853, Acc: 70.22% F1(macro): 0.65: 100%|| 382/382 [03:04<00:00,  2.07it/s]\n",
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 0.755, Acc: 74.09% F1(macro): 0.69: 100%|| 128/128 [00:55<00:00,  2.33it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exptest/best.pt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-d5815a36cbf8>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     76\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     77\u001B[0m \u001B[0;31m# evaluate model with test set\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 78\u001B[0;31m \u001B[0mshufflenet_v2_05_base\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     79\u001B[0m test_loss, test_f1, test_acc = trainer.test(\n\u001B[1;32m     80\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshufflenet_v2_05_base\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_dataloader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mval_dl\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mval_dl\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mtest_dl\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/miniconda/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36mload\u001B[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001B[0m\n\u001B[1;32m    577\u001B[0m         \u001B[0mpickle_load_args\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'encoding'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m'utf-8'\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    578\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 579\u001B[0;31m     \u001B[0;32mwith\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'rb'\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mopened_file\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    580\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0m_is_zipfile\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopened_file\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    581\u001B[0m             \u001B[0;31m# The zipfile reader is going to advance the current file position.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/miniconda/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m_open_file_like\u001B[0;34m(name_or_buffer, mode)\u001B[0m\n\u001B[1;32m    228\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0m_open_file_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_is_path\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 230\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    231\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    232\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;34m'w'\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/miniconda/lib/python3.8/site-packages/torch/serialization.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, name, mode)\u001B[0m\n\u001B[1;32m    209\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0m_open_file\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_opener\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    210\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 211\u001B[0;31m         \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0m_open_file\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    212\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    213\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__exit__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'exptest/best.pt'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.dataloader import create_dataloader\n",
    "from src.loss import CustomCriterion\n",
    "from src.model import Model\n",
    "from src.trainer import TorchTrainer\n",
    "from src.utils.common import get_label_counts, read_yaml\n",
    "from src.utils.macs import calc_macs\n",
    "from src.utils.torch_utils import check_runtime, model_info\n",
    "\n",
    "\n",
    "os.makedirs(\"exptest\", exist_ok=True)\n",
    "model_path = os.path.join(\"exptest\", \"best.pt\")\n",
    "print(f\"Model save path: {model_path}\")\n",
    "\n",
    "\n",
    "\n",
    "data_config = read_yaml(cfg=\"configs/data/taco.yaml\")\n",
    "\n",
    "\n",
    "# Create dataloader\n",
    "train_dl, val_dl, test_dl = create_dataloader(data_config)\n",
    "\n",
    "# Calc macs\n",
    "macs = calc_macs(shufflenet_v2_05_base, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
    "print(f\"macs: {macs}\")\n",
    "\n",
    "# sglee  .\n",
    "# sglee487  .\n",
    "# Create optimizer, scheduler, criterion\n",
    "optimizer = torch.optim.SGD(shufflenet_v2_05_base.parameters(), lr=data_config[\"INIT_LR\"], momentum=0.9)\n",
    "            # adamp.AdamP(model_instance.model.parameters(), lr=data_config[\"INIT_LR\"], weight_decay = 1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer=optimizer,\n",
    "    max_lr=data_config[\"INIT_LR\"],\n",
    "    steps_per_epoch=len(train_dl),\n",
    "    epochs=data_config[\"EPOCHS\"],\n",
    "    pct_start=0.05,\n",
    ")\n",
    "criterion = CustomCriterion(\n",
    "    samples_per_cls=get_label_counts(data_config[\"DATA_PATH\"])\n",
    "    if data_config[\"DATASET\"] == \"TACO\"\n",
    "    else None,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "fp16 = data_config[\"FP16\"]\n",
    "# Amp loss scaler\n",
    "scaler = (\n",
    "    torch.cuda.amp.GradScaler() if fp16 and device != torch.device(\"cpu\") else None\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = TorchTrainer(\n",
    "    model=shufflenet_v2_05_base,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    scaler=scaler,\n",
    "    device=device,\n",
    "    model_path=model_path,\n",
    "    verbose=1,\n",
    ")\n",
    "best_acc, best_f1 = trainer.train(\n",
    "    train_dataloader=train_dl,\n",
    "    n_epoch=data_config[\"EPOCHS\"],\n",
    "    val_dataloader=val_dl if val_dl else test_dl,\n",
    ")\n",
    "\n",
    "# evaluate model with test set\n",
    "shufflenet_v2_05_base.load_state_dict(torch.load(model_path))\n",
    "test_loss, test_f1, test_acc = trainer.test(\n",
    "    model=shufflenet_v2_05_base, test_dataloader=val_dl if val_dl else test_dl\n",
    ")\n",
    "print(test_loss, test_f1, test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleMaxPool2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleConv2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleBatchNorm2d ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleReLU ptflops can affect your code!\n",
      "Warning: variables __flops__ or __params__ are already defined for the moduleLinear ptflops can affect your code!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import argparse\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from src.model import Model\n",
    "from src.augmentation.policies import simple_augment_test\n",
    "from src.utils.common import read_yaml\n",
    "from src.utils.inference_utils import run_model\n",
    "\n",
    "CLASSES = ['Battery', 'Clothing', 'Glass', 'Metal', 'Paper', 'Paperpack', 'Plastic', 'Plasticbag', 'Styrofoam']\n",
    "\n",
    "class CustomImageFolder(ImageFolder):\n",
    "    \"\"\"ImageFolder with filename.\"\"\"\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_gt = super(CustomImageFolder, self).__getitem__(index)\n",
    "        fdir = self.imgs[index][0]\n",
    "        fname = fdir.rsplit(os.path.sep, 1)[-1]\n",
    "        return (img_gt + (fname,))\n",
    "\n",
    "def get_dataloader(img_root: str, data_config: str) -> DataLoader:\n",
    "    \"\"\"Get dataloader.\n",
    "\n",
    "    Note:\n",
    "\tDon't forget to set normalization.\n",
    "    \"\"\"\n",
    "    # Load yaml\n",
    "    data_config = read_yaml(data_config)\n",
    "\n",
    "    transform_test_args = data_confg[\"AUG_TEST_PARAMS\"] if data_config.get(\"AUG_TEST_PARAMS\") else None\n",
    "    # Transformation for test\n",
    "    transform_test = getattr(\n",
    "        __import__(\"src.augmentation.policies\", fromlist=[\"\"]),\n",
    "        data_config[\"AUG_TEST\"],\n",
    "    )(dataset=data_config[\"DATASET\"], img_size=data_config[\"IMG_SIZE\"])\n",
    "\n",
    "    dataset = CustomImageFolder(root=img_root, transform=transform_test)\n",
    "    dataloader = DataLoader(\n",
    "\tdataset=dataset,\n",
    "\tbatch_size=1,\n",
    "\tnum_workers=8\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(model, dataloader, dst_path: str):\n",
    "    result = {}\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    submission_csv = {}\n",
    "    for img, _, fname in dataloader:\n",
    "        img = img.to(device)\n",
    "        pred, enc_data = run_model(model, img)\n",
    "        pred = torch.argmax(pred)\n",
    "        submission_csv[fname[0]] = CLASSES[int(pred.detach())]\n",
    "\n",
    "    result[\"macs\"] = enc_data\n",
    "    result[\"submission\"] = submission_csv\n",
    "    j = json.dumps(result, indent=4)\n",
    "    save_path = os.path.join(dst_path, 'submission.csv')\n",
    "    with open(save_path, 'w') as outfile:\n",
    "        json.dump(result, outfile)\n",
    "\n",
    "dataloader = get_dataloader(img_root='/opt/ml/input/data/test/', data_config='configs/data/taco.yaml')\n",
    "\n",
    "inference(shufflenet_v2_05_base, dataloader, '.')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}