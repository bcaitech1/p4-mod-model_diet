{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# !pwd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/pstage4gun\n"
     ]
    }
   ],
   "source": [
    "# %cd pstage4gun"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import yaml\n",
    "from typing import Any, Dict, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder, VisionDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from src.dataloader import create_dataloader\n",
    "from src.loss import CustomCriterion\n",
    "from src.model import Model\n",
    "from src.trainer import TorchTrainer\n",
    "from src.utils.common import get_label_counts, read_yaml\n",
    "from src.utils.macs import calc_macs\n",
    "from src.utils.torch_utils import check_runtime, model_info\n",
    "\n",
    "CLASSES = ['Battery', 'Clothing', 'Glass', 'Metal', 'Paper', 'Paperpack', 'Plastic', 'Plasticbag', 'Styrofoam']\n",
    "\n",
    "model_config = 'configs/model/mobilenetv3.yaml'\n",
    "weight = 'exp/2021-05-25_14-36-26/best.pt'\n",
    "img_root_val = '/opt/ml/input/data/val/'\n",
    "img_root_test = '/opt/ml/input/data/test/'\n",
    "data_config = 'configs/data/taco.yaml'\n",
    "\n",
    "model_config = read_yaml(cfg=model_config)\n",
    "data_config = read_yaml(cfg=data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def val_inference(\n",
    "    model_config: Dict[str, Any],\n",
    "    data_config: Dict[str, Any],\n",
    "    model_path: str,\n",
    "    fp16: bool,\n",
    "    device: torch.device,\n",
    ") -> Tuple[float, float, float]:\n",
    "\n",
    "    transform_test_params = data_config.get(\"AUG_TEST_PARAMS\")\n",
    "    if not transform_test_params:\n",
    "        transform_test_params = dict()\n",
    "\n",
    "    transform_test = getattr(\n",
    "        __import__(\"src.augmentation.policies\", fromlist=[\"\"]),\n",
    "        data_config[\"AUG_TEST\"],\n",
    "    )(dataset=data_config[\"DATASET\"], img_size=data_config[\"IMG_SIZE\"], **transform_test_params)\n",
    "    val_dataset = ImageFolder(root=os.path.join(data_config['DATA_PATH'], 'val'),\n",
    "                              transform=transform_test)\n",
    "\n",
    "    valid_loader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        pin_memory=(torch.cuda.is_available()),\n",
    "        shuffle=False,\n",
    "        batch_size=data_config[\"BATCH_SIZE\"],\n",
    "        num_workers=5\n",
    "    )\n",
    "\n",
    "    model_instance = Model(model_config, verbose=True)\n",
    "    model_instance.model.to(device)\n",
    "\n",
    "    # Calc macs\n",
    "    macs = calc_macs(model_instance.model, (3, data_config[\"IMG_SIZE\"], data_config[\"IMG_SIZE\"]))\n",
    "    print(f\"macs: {macs}\")\n",
    "\n",
    "    # Create optimizer, scheduler, criterion\n",
    "    criterion = CustomCriterion(\n",
    "        samples_per_cls=get_label_counts(data_config[\"DATA_PATH\"])\n",
    "        if data_config[\"DATASET\"] == \"TACO\"\n",
    "        else None,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    trainer = TorchTrainer(\n",
    "        model=model_instance.model,\n",
    "        criterion=criterion,\n",
    "        optimizer=None,\n",
    "        scheduler=None,\n",
    "        scaler=None,\n",
    "        device=device,\n",
    "        model_path=model_path,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # evaluate model with test set\n",
    "    model_instance.model.load_state_dict(torch.load(model_path))\n",
    "    val_loss, val_f1, val_acc = trainer.test(\n",
    "        model=model_instance.model, test_dataloader=valid_loader\n",
    "    )\n",
    "    return val_loss, val_f1, val_acc, macs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/miniconda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:474: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      " Val:       Loss: 9.237, Acc: 28.39% F1(macro): 0.12: 100%|██████████| 128/128 [00:53<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx |   n |     params |          module |            arguments |   in_channel |   out_channel\n",
      "----------------------------------------------------------------------------------------------\n",
      "  0 |   1 |        464 |            Conv | [16, 3, 2, None, 1, 'HardSwish'] |            3           16\n",
      "  1 |   1 |        464 | InvertedResidualv3 |  [3, 1, 16, 0, 0, 1] |           16           16\n",
      "  2 |   1 |      3,440 | InvertedResidualv3 |  [3, 4, 24, 0, 0, 2] |           16           24\n",
      "  3 |   1 |      4,440 | InvertedResidualv3 |  [3, 3, 24, 0, 0, 1] |           24           24\n",
      "  4 |   1 |     10,328 | InvertedResidualv3 |  [5, 3, 40, 1, 0, 2] |           24           40\n",
      "  5 |   1 |     20,992 | InvertedResidualv3 |  [5, 3, 40, 1, 0, 1] |           40           40\n",
      "  6 |   1 |     20,992 | InvertedResidualv3 |  [5, 3, 40, 1, 0, 1] |           40           40\n",
      "  7 |   1 |     32,080 | InvertedResidualv3 |  [3, 6, 80, 0, 1, 2] |           40           80\n",
      "  8 |   1 |     34,760 | InvertedResidualv3 | [3, 2.5, 80, 0, 1, 1] |           80           80\n",
      "  9 |   1 |     31,992 | InvertedResidualv3 | [3, 2.3, 80, 0, 1, 1] |           80           80\n",
      " 10 |   1 |     31,992 | InvertedResidualv3 | [3, 2.3, 80, 0, 1, 1] |           80           80\n",
      " 11 |   1 |    214,424 | InvertedResidualv3 | [3, 6, 112, 1, 1, 1] |           80          112\n",
      " 12 |   1 |    386,120 | InvertedResidualv3 | [3, 6, 112, 1, 1, 1] |          112          112\n",
      " 13 |   1 |    429,224 | InvertedResidualv3 | [5, 6, 160, 1, 1, 2] |          112          160\n",
      " 14 |   1 |    797,360 | InvertedResidualv3 | [5, 6, 160, 1, 1, 1] |          160          160\n",
      " 15 |   1 |    797,360 | InvertedResidualv3 | [5, 6, 160, 1, 1, 1] |          160          160\n",
      " 16 |   1 |    155,520 |            Conv |          [960, 1, 1] |          160          960\n",
      " 17 |   1 |          0 |   GlobalAvgPool |                   [] |          960          960\n",
      " 18 |   1 |  1,231,360 |            Conv |         [1280, 1, 1] |          960         1280\n",
      " 19 |   1 |          0 |         Flatten |                   [] |         1280         1280\n",
      " 20 |   1 |     11,529 |          Linear |                  [9] |         1280            9\n",
      "Model Summary: 227 layers, 4,214,841 parameters, 4,214,841 gradients\n",
      "macs: 224128545.0\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_f1, val_acc, model_macs = val_inference(\n",
    "    model_config=model_config,\n",
    "    data_config=data_config,\n",
    "    model_path=weight,\n",
    "    fp16=True,\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val score: 17.0277, val f1: 0.1160, MACs: 224128545.0000\n"
     ]
    }
   ],
   "source": [
    "crit_MACs = 13863553\n",
    "crit_F1 = 0.8342\n",
    "\n",
    "score_max = model_macs / crit_MACs\n",
    "if val_f1 < crit_F1:\n",
    "    score_f1 = 1 - (val_f1 / crit_F1)\n",
    "else:\n",
    "    score_f1 = 0.5 * (1 - (val_f1 / crit_F1))\n",
    "\n",
    "score = score_max + score_f1\n",
    "\n",
    "print(f\"val score: {score:.4f}, val f1: {val_f1:.4f}, MACs: {model_macs:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}